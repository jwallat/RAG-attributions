hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

wandb:
  project_name: "rag-attributions"
  mode: "online" #online for syncing

dataset:
  name: "wiki" 
  use_cached_raw_dataset: false
  use_cached_preprocessed_dataset: false
  post_rationalization_ds: ''
  preprocessed_path: 'data/retrievers/${dataset.name}/'

model:
  name: "CohereForAI/c4ai-command-r-plus-4bit"
  # name: "meta-llama/Meta-Llama-3-8B-Instruct"
  batch_size: 4
  generation_config:
    max_new_tokens: 256
    # temperature: 0.0 do_sample=False so temperature is not used

retriever:
  type: "bm25" # or "faiss"
  embedding_model_name: "thenlper/gte-small"
  # embedding_model_name: "thenlper/gte-large"
  # embedding_model_name: "Alibaba-NLP/gte-Qwen2-7B-instruct"
  use_cached_embeddings: false
  cache_dir: "data/retrievers/${dataset.name}/"
  recreate_index: false

reranker:
  model_name: "colbert-ir/colbertv2.0"

# defaults:
#   - override hydra/job_logging: custom